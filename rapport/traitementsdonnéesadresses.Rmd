---
title: "Traitements des données Adresses"
author: "Olivier Leroy"
date: "11/3/2020"
lang: fr-FR
output: 
    bookdown::html_document2:
        theme: readable
        toc: true
        toc_float: true
        number_sections: true
        toc_depth: 3
        fig_caption: true
        keep_md: true
        code_folding: hide
---

# Prétraitements et sources des données

## Sources de données

Le géocodage c'est fait à partir d'un jeu de données constitué via des enquêtes téléphoniques. La nature même des questions comme savoir où habitaient certains sujets lors de leur naissance fait qu'il y a des manques dans le jeu de données (même si dans la mesure du possible un des parents était présent [à confirmer]). 


## Prétraitements des valeurs manquantes 

Le premier traitement a été de repérer des valeurs manquantes (voir "rapport/geocodage_sujet.Rmd" pour plus de précisions) dans les sujets et adresses sans possibilité d'imputation. 

Il y a ainsi :

* 31 sujets sans adresses 
* 14 adresses "terminales" sans localisation 
* 3 adresses peu/pas localisable : en dehors de France, dans des campings

Les deux premieres sont probablement des erreurs d'extractions ou d'encodage et ne doivent pas être gardées. La troisème aurait pu être gardée mais comme nous souhaitons obtenir des informations aériennes nous le l'avons pas non plus garde. Cést aussi ce raisonnement qui nous à pousser à ne pas garder les adresses les départements/territoires d'outre-mer [combien?]. 

# Geocodage

Le gécodage est l'opération de transformation d'une adresse (45 rue Roger Salengro, 42000 Saint-Etienne) en des coordonnées en lat/long.

## Géocodage ESRI + BanR

Deux géocodages en parallèle ont été conduits :

* le premier mené par Matthieu avec la gamme ESRI
* le second par Olivier avec [BanR](https://cran.r-project.org/web/packages/banR/index.html)

La préparation des données, mise en forme et corréction à la marge pour faire le gécoddage avec BanR est disponible dans "Prétraitement_ETL/clean_geocodagev2.R"

Ces deux géocodages ne possédent pas tout à fait les mêmes categories de précisions mais il y a des équivalences : 

ESRI | BanR
---|---
1_PointAdresse | housenumber
2_AdresseInter | NA
3_Voie | street
4_LieuDitHabit | locality
5_ChefLieu | municipality
6_CodePostal | municipality
7_Ville |municipality


Avant d'avoir le géocodage d'ESRI : 193 adresses avait été recodées (Passage sous QGIS avec OSM et utiliation de nominatim et de google map).
Nous sommes partis du géocodage ESRI. 

### Résultats des géocodages

## Schèma géneral

![**Tableau de comparaison entre les différentes catégories de precision**](/home/defuneste/Documents/recherche/gouramic/rapport/geotrait_gouramic.png)

## Ecarts entre les deux geocodages

Une matrice de distance entre les memes points issues des deux géocodage a été produites et tous les cas comprenant un écart de plus de 5 m on été verifier à la main (131 cas). 

La procédure était identique :

1. les données snt exportés dans QGIS avec une visualition OSM

2. l'adresse est localisée en verifiant avec google map/ street view et Nominatim 

3. dans certains cas une recherche web pour trouver des pistes ou des correspondances pouvait être conduite (cas avec des erreurs de frappes dans l'adresse)

4. encodage de la nouvelle adresse dans QGIS

5. relecture du fichier avec R (lors du réassemblage)


Ensuite tous les cas où les deux géocodage donnait une difference ont éte revus:  


![**Tableau de comparaison entre les différentes catégories de precision**](/home/defuneste/Documents/recherche/gouramic/rapport/comparaisongeocodage.jpg)

En plus d'équivalence sur la precision nous avons aussi regarder la précision spatiale. 

Une fois les données resassemblées il était possible d'avoir des points très proches, adresses identiques, non prise en compte comme tels. Nous avons donc procedés à un clustering.

## Clustering pour identifier les doublons

L'evolution du nombre de cluster de plus d'une adresse est présenté dans le graphe suivant. Il représente des clusters à 1, 5, 10, 25, 50, 100, 150 et 200 m de distance. Au vu du graphique les clusters compris entre 1m et 100 m on été verifié visuellement puis éventuellement rassemblé. 

```r
### ici le code est juste donné pour lecture, la matrice est un peu lourde pour calculer
mat_dist <- st_distance(geocodage_adresse.shp)
hc <- hclust(as.dist(mat_dist), method="complete")

# sur d m
d=1

geocodage_adresse.shp$cluster <- cutree(hc, h=d)
# sur une plus grande distance : 50 m cf plot plus bas
geocodage_adresse.shp$bigcluster <- cutree(hc, h=100)
## 2.2 Avec un buffer de d distance et un intersects
# peut être utile de faire un filtre 

buffer_10 <-st_buffer(geocodage_adresse.shp, d)
buffer_50 <- st_buffer(geocodage_adresse.shp, 100) # buffer de 100 m et pas bufer_50 mauvais nom

geocodage_adresse.shp$nb_cluster <-lengths(st_intersects(geocodage_adresse.shp, buffer_10))
geocodage_adresse.shp$nb_bigcluster <-lengths(st_intersects(geocodage_adresse.shp, buffer_50))

rm(hc, buffer_10, buffer_50, mat_dist)

##  2.2 Plot pour regarder l'evolution du clustering en fonction de la distance  ========================

# une fonction de ce qui est fait avec le buffer
number_cluster <- function(data = geocodage_adresse.shp, d) {
                            buffer_XX <- st_buffer(geocodage_adresse.shp, d)
                            dt <- data.frame(d,
                                       sum(lengths(st_intersects(geocodage_adresse.shp, buffer_XX)) != 1))
                            colnames(dt) <- c("d", "nb")
                            return(dt)
}

cluster_dist <- rbind(
    number_cluster(d = 1),
    number_cluster(d = 5),
    number_cluster(d = 10),
    number_cluster(d = 25),
    number_cluster(d = 50),
    number_cluster(d = 100),
    number_cluster(d = 150),
    number_cluster(d = 200)
#    number_cluster(d = 500),
#    number_cluster(d = 1000),
#    number_cluster(d = 10000)
    
)

```

![**Nombre de cluster en fonction de la distance**](/home/defuneste/Documents/recherche/gouramic/rapport/cluster_dist.png)



# Réassamblage, normalisation des données et export dans la base

L'ensemble de ces opérations est disponible dans le script : "Prétraitement_ETL/normalize_adresse.R"

## Données géocodées / géocodées à la main 

```{r}
adresse_commune.dat <- readRDS("../data/adresse")
table(adresse_commune.dat$source_codage)
```


